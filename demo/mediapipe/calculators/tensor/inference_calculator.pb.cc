// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: mediapipe/calculators/tensor/inference_calculator.proto

#include "mediapipe/calculators/tensor/inference_calculator.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG
namespace mediapipe {
constexpr InferenceCalculatorOptions_Delegate_TfLite::InferenceCalculatorOptions_Delegate_TfLite(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized){}
struct InferenceCalculatorOptions_Delegate_TfLiteDefaultTypeInternal {
  constexpr InferenceCalculatorOptions_Delegate_TfLiteDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferenceCalculatorOptions_Delegate_TfLiteDefaultTypeInternal() {}
  union {
    InferenceCalculatorOptions_Delegate_TfLite _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferenceCalculatorOptions_Delegate_TfLiteDefaultTypeInternal _InferenceCalculatorOptions_Delegate_TfLite_default_instance_;
constexpr InferenceCalculatorOptions_Delegate_Gpu::InferenceCalculatorOptions_Delegate_Gpu(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : cached_kernel_path_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , serialized_model_dir_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , model_token_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , use_advanced_gpu_api_(false)
  , api_(0)

  , allow_precision_loss_(true)
  , usage_(2)
{}
struct InferenceCalculatorOptions_Delegate_GpuDefaultTypeInternal {
  constexpr InferenceCalculatorOptions_Delegate_GpuDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferenceCalculatorOptions_Delegate_GpuDefaultTypeInternal() {}
  union {
    InferenceCalculatorOptions_Delegate_Gpu _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferenceCalculatorOptions_Delegate_GpuDefaultTypeInternal _InferenceCalculatorOptions_Delegate_Gpu_default_instance_;
constexpr InferenceCalculatorOptions_Delegate_Nnapi::InferenceCalculatorOptions_Delegate_Nnapi(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : cache_dir_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , model_token_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , accelerator_name_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string){}
struct InferenceCalculatorOptions_Delegate_NnapiDefaultTypeInternal {
  constexpr InferenceCalculatorOptions_Delegate_NnapiDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferenceCalculatorOptions_Delegate_NnapiDefaultTypeInternal() {}
  union {
    InferenceCalculatorOptions_Delegate_Nnapi _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferenceCalculatorOptions_Delegate_NnapiDefaultTypeInternal _InferenceCalculatorOptions_Delegate_Nnapi_default_instance_;
constexpr InferenceCalculatorOptions_Delegate_Xnnpack::InferenceCalculatorOptions_Delegate_Xnnpack(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : num_threads_(-1){}
struct InferenceCalculatorOptions_Delegate_XnnpackDefaultTypeInternal {
  constexpr InferenceCalculatorOptions_Delegate_XnnpackDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferenceCalculatorOptions_Delegate_XnnpackDefaultTypeInternal() {}
  union {
    InferenceCalculatorOptions_Delegate_Xnnpack _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferenceCalculatorOptions_Delegate_XnnpackDefaultTypeInternal _InferenceCalculatorOptions_Delegate_Xnnpack_default_instance_;
constexpr InferenceCalculatorOptions_Delegate::InferenceCalculatorOptions_Delegate(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : _oneof_case_{}{}
struct InferenceCalculatorOptions_DelegateDefaultTypeInternal {
  constexpr InferenceCalculatorOptions_DelegateDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferenceCalculatorOptions_DelegateDefaultTypeInternal() {}
  union {
    InferenceCalculatorOptions_Delegate _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferenceCalculatorOptions_DelegateDefaultTypeInternal _InferenceCalculatorOptions_Delegate_default_instance_;
constexpr InferenceCalculatorOptions::InferenceCalculatorOptions(
  ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized)
  : model_path_(&::PROTOBUF_NAMESPACE_ID::internal::fixed_address_empty_string)
  , delegate_(nullptr)
  , use_gpu_(false)
  , use_nnapi_(false)
  , cpu_num_thread_(-1){}
struct InferenceCalculatorOptionsDefaultTypeInternal {
  constexpr InferenceCalculatorOptionsDefaultTypeInternal()
    : _instance(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized{}) {}
  ~InferenceCalculatorOptionsDefaultTypeInternal() {}
  union {
    InferenceCalculatorOptions _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT InferenceCalculatorOptionsDefaultTypeInternal _InferenceCalculatorOptions_default_instance_;
}  // namespace mediapipe
static ::PROTOBUF_NAMESPACE_ID::Metadata file_level_metadata_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto[6];
static const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* file_level_enum_descriptors_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto[2];
static constexpr ::PROTOBUF_NAMESPACE_ID::ServiceDescriptor const** file_level_service_descriptors_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto = nullptr;

const uint32_t TableStruct_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_TfLite, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Gpu, _has_bits_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Gpu, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Gpu, use_advanced_gpu_api_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Gpu, api_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Gpu, allow_precision_loss_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Gpu, cached_kernel_path_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Gpu, serialized_model_dir_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Gpu, model_token_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Gpu, usage_),
  3,
  4,
  5,
  0,
  1,
  2,
  6,
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi, _has_bits_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi, cache_dir_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi, model_token_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi, accelerator_name_),
  0,
  1,
  2,
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Xnnpack, _has_bits_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Xnnpack, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate_Xnnpack, num_threads_),
  0,
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate, _internal_metadata_),
  ~0u,  // no _extensions_
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate, _oneof_case_[0]),
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ::PROTOBUF_NAMESPACE_ID::internal::kInvalidFieldOffsetTag,
  ::PROTOBUF_NAMESPACE_ID::internal::kInvalidFieldOffsetTag,
  ::PROTOBUF_NAMESPACE_ID::internal::kInvalidFieldOffsetTag,
  ::PROTOBUF_NAMESPACE_ID::internal::kInvalidFieldOffsetTag,
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions_Delegate, delegate_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions, _has_bits_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions, model_path_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions, use_gpu_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions, use_nnapi_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions, cpu_num_thread_),
  PROTOBUF_FIELD_OFFSET(::mediapipe::InferenceCalculatorOptions, delegate_),
  0,
  2,
  3,
  4,
  1,
};
static const ::PROTOBUF_NAMESPACE_ID::internal::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, -1, sizeof(::mediapipe::InferenceCalculatorOptions_Delegate_TfLite)},
  { 6, 19, -1, sizeof(::mediapipe::InferenceCalculatorOptions_Delegate_Gpu)},
  { 26, 35, -1, sizeof(::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi)},
  { 38, 45, -1, sizeof(::mediapipe::InferenceCalculatorOptions_Delegate_Xnnpack)},
  { 46, -1, -1, sizeof(::mediapipe::InferenceCalculatorOptions_Delegate)},
  { 57, 68, -1, sizeof(::mediapipe::InferenceCalculatorOptions)},
};

static ::PROTOBUF_NAMESPACE_ID::Message const * const file_default_instances[] = {
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::mediapipe::_InferenceCalculatorOptions_Delegate_TfLite_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::mediapipe::_InferenceCalculatorOptions_Delegate_Gpu_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::mediapipe::_InferenceCalculatorOptions_Delegate_Nnapi_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::mediapipe::_InferenceCalculatorOptions_Delegate_Xnnpack_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::mediapipe::_InferenceCalculatorOptions_Delegate_default_instance_),
  reinterpret_cast<const ::PROTOBUF_NAMESPACE_ID::Message*>(&::mediapipe::_InferenceCalculatorOptions_default_instance_),
};

const char descriptor_table_protodef_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n7mediapipe/calculators/tensor/inference"
  "_calculator.proto\022\tmediapipe\032$mediapipe/"
  "framework/calculator.proto\"\223\t\n\032Inference"
  "CalculatorOptions\022\022\n\nmodel_path\030\001 \001(\t\022\032\n"
  "\007use_gpu\030\002 \001(\010:\005falseB\002\030\001\022\034\n\tuse_nnapi\030\003"
  " \001(\010:\005falseB\002\030\001\022\032\n\016cpu_num_thread\030\004 \001(\005:"
  "\002-1\022@\n\010delegate\030\005 \001(\0132..mediapipe.Infere"
  "nceCalculatorOptions.Delegate\032\362\006\n\010Delega"
  "te\022G\n\006tflite\030\001 \001(\01325.mediapipe.Inference"
  "CalculatorOptions.Delegate.TfLiteH\000\022A\n\003g"
  "pu\030\002 \001(\01322.mediapipe.InferenceCalculator"
  "Options.Delegate.GpuH\000\022E\n\005nnapi\030\003 \001(\01324."
  "mediapipe.InferenceCalculatorOptions.Del"
  "egate.NnapiH\000\022I\n\007xnnpack\030\004 \001(\01326.mediapi"
  "pe.InferenceCalculatorOptions.Delegate.X"
  "nnpackH\000\032\010\n\006TfLite\032\302\003\n\003Gpu\022#\n\024use_advanc"
  "ed_gpu_api\030\001 \001(\010:\005false\022H\n\003api\030\004 \001(\01626.m"
  "ediapipe.InferenceCalculatorOptions.Dele"
  "gate.Gpu.Api:\003ANY\022\"\n\024allow_precision_los"
  "s\030\003 \001(\010:\004true\022\032\n\022cached_kernel_path\030\002 \001("
  "\t\022\034\n\024serialized_model_dir\030\007 \001(\t\022\023\n\013model"
  "_token\030\010 \001(\t\022a\n\005usage\030\005 \001(\0162A.mediapipe."
  "InferenceCalculatorOptions.Delegate.Gpu."
  "InferenceUsage:\017SUSTAINED_SPEED\"&\n\003Api\022\007"
  "\n\003ANY\020\000\022\n\n\006OPENGL\020\001\022\n\n\006OPENCL\020\002\"N\n\016Infer"
  "enceUsage\022\017\n\013UNSPECIFIED\020\000\022\026\n\022FAST_SINGL"
  "E_ANSWER\020\001\022\023\n\017SUSTAINED_SPEED\020\002\032I\n\005Nnapi"
  "\022\021\n\tcache_dir\030\001 \001(\t\022\023\n\013model_token\030\002 \001(\t"
  "\022\030\n\020accelerator_name\030\003 \001(\t\032\"\n\007Xnnpack\022\027\n"
  "\013num_threads\030\001 \001(\005:\002-1B\n\n\010delegate2T\n\003ex"
  "t\022\034.mediapipe.CalculatorOptions\030\367\323\313\240\001 \001("
  "\0132%.mediapipe.InferenceCalculatorOptions"
  "BA\n%com.google.mediapipe.calculator.prot"
  "oB\030InferenceCalculatorProto"
  ;
static const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable*const descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_deps[1] = {
  &::descriptor_table_mediapipe_2fframework_2fcalculator_2eproto,
};
static ::PROTOBUF_NAMESPACE_ID::internal::once_flag descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_once;
const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto = {
  false, false, 1347, descriptor_table_protodef_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto, "mediapipe/calculators/tensor/inference_calculator.proto", 
  &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_once, descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_deps, 1, 6,
  schemas, file_default_instances, TableStruct_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto::offsets,
  file_level_metadata_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto, file_level_enum_descriptors_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto, file_level_service_descriptors_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto,
};
PROTOBUF_ATTRIBUTE_WEAK const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable* descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_getter() {
  return &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto;
}

// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY static ::PROTOBUF_NAMESPACE_ID::internal::AddDescriptorsRunner dynamic_init_dummy_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto(&descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto);
namespace mediapipe {
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* InferenceCalculatorOptions_Delegate_Gpu_Api_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto);
  return file_level_enum_descriptors_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto[0];
}
bool InferenceCalculatorOptions_Delegate_Gpu_Api_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr InferenceCalculatorOptions_Delegate_Gpu_Api InferenceCalculatorOptions_Delegate_Gpu::ANY;
constexpr InferenceCalculatorOptions_Delegate_Gpu_Api InferenceCalculatorOptions_Delegate_Gpu::OPENGL;
constexpr InferenceCalculatorOptions_Delegate_Gpu_Api InferenceCalculatorOptions_Delegate_Gpu::OPENCL;
constexpr InferenceCalculatorOptions_Delegate_Gpu_Api InferenceCalculatorOptions_Delegate_Gpu::Api_MIN;
constexpr InferenceCalculatorOptions_Delegate_Gpu_Api InferenceCalculatorOptions_Delegate_Gpu::Api_MAX;
constexpr int InferenceCalculatorOptions_Delegate_Gpu::Api_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage_descriptor() {
  ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(&descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto);
  return file_level_enum_descriptors_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto[1];
}
bool InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage_IsValid(int value) {
  switch (value) {
    case 0:
    case 1:
    case 2:
      return true;
    default:
      return false;
  }
}

#if (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))
constexpr InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage InferenceCalculatorOptions_Delegate_Gpu::UNSPECIFIED;
constexpr InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage InferenceCalculatorOptions_Delegate_Gpu::FAST_SINGLE_ANSWER;
constexpr InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage InferenceCalculatorOptions_Delegate_Gpu::SUSTAINED_SPEED;
constexpr InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage InferenceCalculatorOptions_Delegate_Gpu::InferenceUsage_MIN;
constexpr InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage InferenceCalculatorOptions_Delegate_Gpu::InferenceUsage_MAX;
constexpr int InferenceCalculatorOptions_Delegate_Gpu::InferenceUsage_ARRAYSIZE;
#endif  // (__cplusplus < 201703) && (!defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912))

// ===================================================================

class InferenceCalculatorOptions_Delegate_TfLite::_Internal {
 public:
};

InferenceCalculatorOptions_Delegate_TfLite::InferenceCalculatorOptions_Delegate_TfLite(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase(arena, is_message_owned) {
  // @@protoc_insertion_point(arena_constructor:mediapipe.InferenceCalculatorOptions.Delegate.TfLite)
}
InferenceCalculatorOptions_Delegate_TfLite::InferenceCalculatorOptions_Delegate_TfLite(const InferenceCalculatorOptions_Delegate_TfLite& from)
  : ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase() {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:mediapipe.InferenceCalculatorOptions.Delegate.TfLite)
}





const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferenceCalculatorOptions_Delegate_TfLite::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::CopyImpl,
    ::PROTOBUF_NAMESPACE_ID::internal::ZeroFieldsBase::MergeImpl,
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferenceCalculatorOptions_Delegate_TfLite::GetClassData() const { return &_class_data_; }







::PROTOBUF_NAMESPACE_ID::Metadata InferenceCalculatorOptions_Delegate_TfLite::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_getter, &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_once,
      file_level_metadata_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto[0]);
}

// ===================================================================

class InferenceCalculatorOptions_Delegate_Gpu::_Internal {
 public:
  using HasBits = decltype(std::declval<InferenceCalculatorOptions_Delegate_Gpu>()._has_bits_);
  static void set_has_use_advanced_gpu_api(HasBits* has_bits) {
    (*has_bits)[0] |= 8u;
  }
  static void set_has_api(HasBits* has_bits) {
    (*has_bits)[0] |= 16u;
  }
  static void set_has_allow_precision_loss(HasBits* has_bits) {
    (*has_bits)[0] |= 32u;
  }
  static void set_has_cached_kernel_path(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
  static void set_has_serialized_model_dir(HasBits* has_bits) {
    (*has_bits)[0] |= 2u;
  }
  static void set_has_model_token(HasBits* has_bits) {
    (*has_bits)[0] |= 4u;
  }
  static void set_has_usage(HasBits* has_bits) {
    (*has_bits)[0] |= 64u;
  }
};

InferenceCalculatorOptions_Delegate_Gpu::InferenceCalculatorOptions_Delegate_Gpu(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:mediapipe.InferenceCalculatorOptions.Delegate.Gpu)
}
InferenceCalculatorOptions_Delegate_Gpu::InferenceCalculatorOptions_Delegate_Gpu(const InferenceCalculatorOptions_Delegate_Gpu& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  cached_kernel_path_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    cached_kernel_path_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (from._internal_has_cached_kernel_path()) {
    cached_kernel_path_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_cached_kernel_path(), 
      GetArenaForAllocation());
  }
  serialized_model_dir_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    serialized_model_dir_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (from._internal_has_serialized_model_dir()) {
    serialized_model_dir_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_serialized_model_dir(), 
      GetArenaForAllocation());
  }
  model_token_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    model_token_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (from._internal_has_model_token()) {
    model_token_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_model_token(), 
      GetArenaForAllocation());
  }
  ::memcpy(&use_advanced_gpu_api_, &from.use_advanced_gpu_api_,
    static_cast<size_t>(reinterpret_cast<char*>(&usage_) -
    reinterpret_cast<char*>(&use_advanced_gpu_api_)) + sizeof(usage_));
  // @@protoc_insertion_point(copy_constructor:mediapipe.InferenceCalculatorOptions.Delegate.Gpu)
}

inline void InferenceCalculatorOptions_Delegate_Gpu::SharedCtor() {
cached_kernel_path_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  cached_kernel_path_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
serialized_model_dir_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  serialized_model_dir_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
model_token_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  model_token_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
::memset(reinterpret_cast<char*>(this) + static_cast<size_t>(
    reinterpret_cast<char*>(&use_advanced_gpu_api_) - reinterpret_cast<char*>(this)),
    0, static_cast<size_t>(reinterpret_cast<char*>(&api_) -
    reinterpret_cast<char*>(&use_advanced_gpu_api_)) + sizeof(api_));
allow_precision_loss_ = true;
usage_ = 2;
}

InferenceCalculatorOptions_Delegate_Gpu::~InferenceCalculatorOptions_Delegate_Gpu() {
  // @@protoc_insertion_point(destructor:mediapipe.InferenceCalculatorOptions.Delegate.Gpu)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferenceCalculatorOptions_Delegate_Gpu::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  cached_kernel_path_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  serialized_model_dir_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  model_token_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}

void InferenceCalculatorOptions_Delegate_Gpu::ArenaDtor(void* object) {
  InferenceCalculatorOptions_Delegate_Gpu* _this = reinterpret_cast< InferenceCalculatorOptions_Delegate_Gpu* >(object);
  (void)_this;
}
void InferenceCalculatorOptions_Delegate_Gpu::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferenceCalculatorOptions_Delegate_Gpu::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferenceCalculatorOptions_Delegate_Gpu::Clear() {
// @@protoc_insertion_point(message_clear_start:mediapipe.InferenceCalculatorOptions.Delegate.Gpu)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000007u) {
    if (cached_has_bits & 0x00000001u) {
      cached_kernel_path_.ClearNonDefaultToEmpty();
    }
    if (cached_has_bits & 0x00000002u) {
      serialized_model_dir_.ClearNonDefaultToEmpty();
    }
    if (cached_has_bits & 0x00000004u) {
      model_token_.ClearNonDefaultToEmpty();
    }
  }
  if (cached_has_bits & 0x00000078u) {
    ::memset(&use_advanced_gpu_api_, 0, static_cast<size_t>(
        reinterpret_cast<char*>(&api_) -
        reinterpret_cast<char*>(&use_advanced_gpu_api_)) + sizeof(api_));
    allow_precision_loss_ = true;
    usage_ = 2;
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferenceCalculatorOptions_Delegate_Gpu::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  _Internal::HasBits has_bits{};
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // optional bool use_advanced_gpu_api = 1 [default = false];
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _Internal::set_has_use_advanced_gpu_api(&has_bits);
          use_advanced_gpu_api_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional string cached_kernel_path = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          auto str = _internal_mutable_cached_kernel_path();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          #ifndef NDEBUG
          ::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "mediapipe.InferenceCalculatorOptions.Delegate.Gpu.cached_kernel_path");
          #endif  // !NDEBUG
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional bool allow_precision_loss = 3 [default = true];
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _Internal::set_has_allow_precision_loss(&has_bits);
          allow_precision_loss_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional .mediapipe.InferenceCalculatorOptions.Delegate.Gpu.Api api = 4 [default = ANY];
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          if (PROTOBUF_PREDICT_TRUE(::mediapipe::InferenceCalculatorOptions_Delegate_Gpu_Api_IsValid(val))) {
            _internal_set_api(static_cast<::mediapipe::InferenceCalculatorOptions_Delegate_Gpu_Api>(val));
          } else {
            ::PROTOBUF_NAMESPACE_ID::internal::WriteVarint(4, val, mutable_unknown_fields());
          }
        } else
          goto handle_unusual;
        continue;
      // optional .mediapipe.InferenceCalculatorOptions.Delegate.Gpu.InferenceUsage usage = 5 [default = SUSTAINED_SPEED];
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 40)) {
          uint64_t val = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
          if (PROTOBUF_PREDICT_TRUE(::mediapipe::InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage_IsValid(val))) {
            _internal_set_usage(static_cast<::mediapipe::InferenceCalculatorOptions_Delegate_Gpu_InferenceUsage>(val));
          } else {
            ::PROTOBUF_NAMESPACE_ID::internal::WriteVarint(5, val, mutable_unknown_fields());
          }
        } else
          goto handle_unusual;
        continue;
      // optional string serialized_model_dir = 7;
      case 7:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 58)) {
          auto str = _internal_mutable_serialized_model_dir();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          #ifndef NDEBUG
          ::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "mediapipe.InferenceCalculatorOptions.Delegate.Gpu.serialized_model_dir");
          #endif  // !NDEBUG
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional string model_token = 8;
      case 8:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 66)) {
          auto str = _internal_mutable_model_token();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          #ifndef NDEBUG
          ::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "mediapipe.InferenceCalculatorOptions.Delegate.Gpu.model_token");
          #endif  // !NDEBUG
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  _has_bits_.Or(has_bits);
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferenceCalculatorOptions_Delegate_Gpu::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:mediapipe.InferenceCalculatorOptions.Delegate.Gpu)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // optional bool use_advanced_gpu_api = 1 [default = false];
  if (cached_has_bits & 0x00000008u) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteBoolToArray(1, this->_internal_use_advanced_gpu_api(), target);
  }

  // optional string cached_kernel_path = 2;
  if (cached_has_bits & 0x00000001u) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::VerifyUTF8StringNamedField(
      this->_internal_cached_kernel_path().data(), static_cast<int>(this->_internal_cached_kernel_path().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SERIALIZE,
      "mediapipe.InferenceCalculatorOptions.Delegate.Gpu.cached_kernel_path");
    target = stream->WriteStringMaybeAliased(
        2, this->_internal_cached_kernel_path(), target);
  }

  // optional bool allow_precision_loss = 3 [default = true];
  if (cached_has_bits & 0x00000020u) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteBoolToArray(3, this->_internal_allow_precision_loss(), target);
  }

  // optional .mediapipe.InferenceCalculatorOptions.Delegate.Gpu.Api api = 4 [default = ANY];
  if (cached_has_bits & 0x00000010u) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteEnumToArray(
      4, this->_internal_api(), target);
  }

  // optional .mediapipe.InferenceCalculatorOptions.Delegate.Gpu.InferenceUsage usage = 5 [default = SUSTAINED_SPEED];
  if (cached_has_bits & 0x00000040u) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteEnumToArray(
      5, this->_internal_usage(), target);
  }

  // optional string serialized_model_dir = 7;
  if (cached_has_bits & 0x00000002u) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::VerifyUTF8StringNamedField(
      this->_internal_serialized_model_dir().data(), static_cast<int>(this->_internal_serialized_model_dir().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SERIALIZE,
      "mediapipe.InferenceCalculatorOptions.Delegate.Gpu.serialized_model_dir");
    target = stream->WriteStringMaybeAliased(
        7, this->_internal_serialized_model_dir(), target);
  }

  // optional string model_token = 8;
  if (cached_has_bits & 0x00000004u) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::VerifyUTF8StringNamedField(
      this->_internal_model_token().data(), static_cast<int>(this->_internal_model_token().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SERIALIZE,
      "mediapipe.InferenceCalculatorOptions.Delegate.Gpu.model_token");
    target = stream->WriteStringMaybeAliased(
        8, this->_internal_model_token(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:mediapipe.InferenceCalculatorOptions.Delegate.Gpu)
  return target;
}

size_t InferenceCalculatorOptions_Delegate_Gpu::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:mediapipe.InferenceCalculatorOptions.Delegate.Gpu)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x0000007fu) {
    // optional string cached_kernel_path = 2;
    if (cached_has_bits & 0x00000001u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
          this->_internal_cached_kernel_path());
    }

    // optional string serialized_model_dir = 7;
    if (cached_has_bits & 0x00000002u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
          this->_internal_serialized_model_dir());
    }

    // optional string model_token = 8;
    if (cached_has_bits & 0x00000004u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
          this->_internal_model_token());
    }

    // optional bool use_advanced_gpu_api = 1 [default = false];
    if (cached_has_bits & 0x00000008u) {
      total_size += 1 + 1;
    }

    // optional .mediapipe.InferenceCalculatorOptions.Delegate.Gpu.Api api = 4 [default = ANY];
    if (cached_has_bits & 0x00000010u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::EnumSize(this->_internal_api());
    }

    // optional bool allow_precision_loss = 3 [default = true];
    if (cached_has_bits & 0x00000020u) {
      total_size += 1 + 1;
    }

    // optional .mediapipe.InferenceCalculatorOptions.Delegate.Gpu.InferenceUsage usage = 5 [default = SUSTAINED_SPEED];
    if (cached_has_bits & 0x00000040u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::EnumSize(this->_internal_usage());
    }

  }
  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferenceCalculatorOptions_Delegate_Gpu::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferenceCalculatorOptions_Delegate_Gpu::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferenceCalculatorOptions_Delegate_Gpu::GetClassData() const { return &_class_data_; }

void InferenceCalculatorOptions_Delegate_Gpu::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferenceCalculatorOptions_Delegate_Gpu *>(to)->MergeFrom(
      static_cast<const InferenceCalculatorOptions_Delegate_Gpu &>(from));
}


void InferenceCalculatorOptions_Delegate_Gpu::MergeFrom(const InferenceCalculatorOptions_Delegate_Gpu& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:mediapipe.InferenceCalculatorOptions.Delegate.Gpu)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 0x0000007fu) {
    if (cached_has_bits & 0x00000001u) {
      _internal_set_cached_kernel_path(from._internal_cached_kernel_path());
    }
    if (cached_has_bits & 0x00000002u) {
      _internal_set_serialized_model_dir(from._internal_serialized_model_dir());
    }
    if (cached_has_bits & 0x00000004u) {
      _internal_set_model_token(from._internal_model_token());
    }
    if (cached_has_bits & 0x00000008u) {
      use_advanced_gpu_api_ = from.use_advanced_gpu_api_;
    }
    if (cached_has_bits & 0x00000010u) {
      api_ = from.api_;
    }
    if (cached_has_bits & 0x00000020u) {
      allow_precision_loss_ = from.allow_precision_loss_;
    }
    if (cached_has_bits & 0x00000040u) {
      usage_ = from.usage_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferenceCalculatorOptions_Delegate_Gpu::CopyFrom(const InferenceCalculatorOptions_Delegate_Gpu& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:mediapipe.InferenceCalculatorOptions.Delegate.Gpu)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferenceCalculatorOptions_Delegate_Gpu::IsInitialized() const {
  return true;
}

void InferenceCalculatorOptions_Delegate_Gpu::InternalSwap(InferenceCalculatorOptions_Delegate_Gpu* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &cached_kernel_path_, lhs_arena,
      &other->cached_kernel_path_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &serialized_model_dir_, lhs_arena,
      &other->serialized_model_dir_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &model_token_, lhs_arena,
      &other->model_token_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(InferenceCalculatorOptions_Delegate_Gpu, api_)
      + sizeof(InferenceCalculatorOptions_Delegate_Gpu::api_)
      - PROTOBUF_FIELD_OFFSET(InferenceCalculatorOptions_Delegate_Gpu, use_advanced_gpu_api_)>(
          reinterpret_cast<char*>(&use_advanced_gpu_api_),
          reinterpret_cast<char*>(&other->use_advanced_gpu_api_));
  swap(allow_precision_loss_, other->allow_precision_loss_);
  swap(usage_, other->usage_);
}

::PROTOBUF_NAMESPACE_ID::Metadata InferenceCalculatorOptions_Delegate_Gpu::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_getter, &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_once,
      file_level_metadata_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto[1]);
}

// ===================================================================

class InferenceCalculatorOptions_Delegate_Nnapi::_Internal {
 public:
  using HasBits = decltype(std::declval<InferenceCalculatorOptions_Delegate_Nnapi>()._has_bits_);
  static void set_has_cache_dir(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
  static void set_has_model_token(HasBits* has_bits) {
    (*has_bits)[0] |= 2u;
  }
  static void set_has_accelerator_name(HasBits* has_bits) {
    (*has_bits)[0] |= 4u;
  }
};

InferenceCalculatorOptions_Delegate_Nnapi::InferenceCalculatorOptions_Delegate_Nnapi(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:mediapipe.InferenceCalculatorOptions.Delegate.Nnapi)
}
InferenceCalculatorOptions_Delegate_Nnapi::InferenceCalculatorOptions_Delegate_Nnapi(const InferenceCalculatorOptions_Delegate_Nnapi& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  cache_dir_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    cache_dir_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (from._internal_has_cache_dir()) {
    cache_dir_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_cache_dir(), 
      GetArenaForAllocation());
  }
  model_token_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    model_token_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (from._internal_has_model_token()) {
    model_token_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_model_token(), 
      GetArenaForAllocation());
  }
  accelerator_name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    accelerator_name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (from._internal_has_accelerator_name()) {
    accelerator_name_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_accelerator_name(), 
      GetArenaForAllocation());
  }
  // @@protoc_insertion_point(copy_constructor:mediapipe.InferenceCalculatorOptions.Delegate.Nnapi)
}

inline void InferenceCalculatorOptions_Delegate_Nnapi::SharedCtor() {
cache_dir_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  cache_dir_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
model_token_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  model_token_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
accelerator_name_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  accelerator_name_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

InferenceCalculatorOptions_Delegate_Nnapi::~InferenceCalculatorOptions_Delegate_Nnapi() {
  // @@protoc_insertion_point(destructor:mediapipe.InferenceCalculatorOptions.Delegate.Nnapi)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferenceCalculatorOptions_Delegate_Nnapi::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  cache_dir_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  model_token_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  accelerator_name_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
}

void InferenceCalculatorOptions_Delegate_Nnapi::ArenaDtor(void* object) {
  InferenceCalculatorOptions_Delegate_Nnapi* _this = reinterpret_cast< InferenceCalculatorOptions_Delegate_Nnapi* >(object);
  (void)_this;
}
void InferenceCalculatorOptions_Delegate_Nnapi::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferenceCalculatorOptions_Delegate_Nnapi::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferenceCalculatorOptions_Delegate_Nnapi::Clear() {
// @@protoc_insertion_point(message_clear_start:mediapipe.InferenceCalculatorOptions.Delegate.Nnapi)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000007u) {
    if (cached_has_bits & 0x00000001u) {
      cache_dir_.ClearNonDefaultToEmpty();
    }
    if (cached_has_bits & 0x00000002u) {
      model_token_.ClearNonDefaultToEmpty();
    }
    if (cached_has_bits & 0x00000004u) {
      accelerator_name_.ClearNonDefaultToEmpty();
    }
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferenceCalculatorOptions_Delegate_Nnapi::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  _Internal::HasBits has_bits{};
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // optional string cache_dir = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_cache_dir();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          #ifndef NDEBUG
          ::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "mediapipe.InferenceCalculatorOptions.Delegate.Nnapi.cache_dir");
          #endif  // !NDEBUG
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional string model_token = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          auto str = _internal_mutable_model_token();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          #ifndef NDEBUG
          ::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "mediapipe.InferenceCalculatorOptions.Delegate.Nnapi.model_token");
          #endif  // !NDEBUG
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional string accelerator_name = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          auto str = _internal_mutable_accelerator_name();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          #ifndef NDEBUG
          ::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "mediapipe.InferenceCalculatorOptions.Delegate.Nnapi.accelerator_name");
          #endif  // !NDEBUG
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  _has_bits_.Or(has_bits);
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferenceCalculatorOptions_Delegate_Nnapi::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:mediapipe.InferenceCalculatorOptions.Delegate.Nnapi)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // optional string cache_dir = 1;
  if (cached_has_bits & 0x00000001u) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::VerifyUTF8StringNamedField(
      this->_internal_cache_dir().data(), static_cast<int>(this->_internal_cache_dir().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SERIALIZE,
      "mediapipe.InferenceCalculatorOptions.Delegate.Nnapi.cache_dir");
    target = stream->WriteStringMaybeAliased(
        1, this->_internal_cache_dir(), target);
  }

  // optional string model_token = 2;
  if (cached_has_bits & 0x00000002u) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::VerifyUTF8StringNamedField(
      this->_internal_model_token().data(), static_cast<int>(this->_internal_model_token().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SERIALIZE,
      "mediapipe.InferenceCalculatorOptions.Delegate.Nnapi.model_token");
    target = stream->WriteStringMaybeAliased(
        2, this->_internal_model_token(), target);
  }

  // optional string accelerator_name = 3;
  if (cached_has_bits & 0x00000004u) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::VerifyUTF8StringNamedField(
      this->_internal_accelerator_name().data(), static_cast<int>(this->_internal_accelerator_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SERIALIZE,
      "mediapipe.InferenceCalculatorOptions.Delegate.Nnapi.accelerator_name");
    target = stream->WriteStringMaybeAliased(
        3, this->_internal_accelerator_name(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:mediapipe.InferenceCalculatorOptions.Delegate.Nnapi)
  return target;
}

size_t InferenceCalculatorOptions_Delegate_Nnapi::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:mediapipe.InferenceCalculatorOptions.Delegate.Nnapi)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000007u) {
    // optional string cache_dir = 1;
    if (cached_has_bits & 0x00000001u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
          this->_internal_cache_dir());
    }

    // optional string model_token = 2;
    if (cached_has_bits & 0x00000002u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
          this->_internal_model_token());
    }

    // optional string accelerator_name = 3;
    if (cached_has_bits & 0x00000004u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
          this->_internal_accelerator_name());
    }

  }
  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferenceCalculatorOptions_Delegate_Nnapi::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferenceCalculatorOptions_Delegate_Nnapi::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferenceCalculatorOptions_Delegate_Nnapi::GetClassData() const { return &_class_data_; }

void InferenceCalculatorOptions_Delegate_Nnapi::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferenceCalculatorOptions_Delegate_Nnapi *>(to)->MergeFrom(
      static_cast<const InferenceCalculatorOptions_Delegate_Nnapi &>(from));
}


void InferenceCalculatorOptions_Delegate_Nnapi::MergeFrom(const InferenceCalculatorOptions_Delegate_Nnapi& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:mediapipe.InferenceCalculatorOptions.Delegate.Nnapi)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 0x00000007u) {
    if (cached_has_bits & 0x00000001u) {
      _internal_set_cache_dir(from._internal_cache_dir());
    }
    if (cached_has_bits & 0x00000002u) {
      _internal_set_model_token(from._internal_model_token());
    }
    if (cached_has_bits & 0x00000004u) {
      _internal_set_accelerator_name(from._internal_accelerator_name());
    }
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferenceCalculatorOptions_Delegate_Nnapi::CopyFrom(const InferenceCalculatorOptions_Delegate_Nnapi& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:mediapipe.InferenceCalculatorOptions.Delegate.Nnapi)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferenceCalculatorOptions_Delegate_Nnapi::IsInitialized() const {
  return true;
}

void InferenceCalculatorOptions_Delegate_Nnapi::InternalSwap(InferenceCalculatorOptions_Delegate_Nnapi* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &cache_dir_, lhs_arena,
      &other->cache_dir_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &model_token_, lhs_arena,
      &other->model_token_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &accelerator_name_, lhs_arena,
      &other->accelerator_name_, rhs_arena
  );
}

::PROTOBUF_NAMESPACE_ID::Metadata InferenceCalculatorOptions_Delegate_Nnapi::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_getter, &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_once,
      file_level_metadata_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto[2]);
}

// ===================================================================

class InferenceCalculatorOptions_Delegate_Xnnpack::_Internal {
 public:
  using HasBits = decltype(std::declval<InferenceCalculatorOptions_Delegate_Xnnpack>()._has_bits_);
  static void set_has_num_threads(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
};

InferenceCalculatorOptions_Delegate_Xnnpack::InferenceCalculatorOptions_Delegate_Xnnpack(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:mediapipe.InferenceCalculatorOptions.Delegate.Xnnpack)
}
InferenceCalculatorOptions_Delegate_Xnnpack::InferenceCalculatorOptions_Delegate_Xnnpack(const InferenceCalculatorOptions_Delegate_Xnnpack& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  num_threads_ = from.num_threads_;
  // @@protoc_insertion_point(copy_constructor:mediapipe.InferenceCalculatorOptions.Delegate.Xnnpack)
}

inline void InferenceCalculatorOptions_Delegate_Xnnpack::SharedCtor() {
num_threads_ = -1;
}

InferenceCalculatorOptions_Delegate_Xnnpack::~InferenceCalculatorOptions_Delegate_Xnnpack() {
  // @@protoc_insertion_point(destructor:mediapipe.InferenceCalculatorOptions.Delegate.Xnnpack)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferenceCalculatorOptions_Delegate_Xnnpack::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void InferenceCalculatorOptions_Delegate_Xnnpack::ArenaDtor(void* object) {
  InferenceCalculatorOptions_Delegate_Xnnpack* _this = reinterpret_cast< InferenceCalculatorOptions_Delegate_Xnnpack* >(object);
  (void)_this;
}
void InferenceCalculatorOptions_Delegate_Xnnpack::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferenceCalculatorOptions_Delegate_Xnnpack::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferenceCalculatorOptions_Delegate_Xnnpack::Clear() {
// @@protoc_insertion_point(message_clear_start:mediapipe.InferenceCalculatorOptions.Delegate.Xnnpack)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  num_threads_ = -1;
  _has_bits_.Clear();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferenceCalculatorOptions_Delegate_Xnnpack::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  _Internal::HasBits has_bits{};
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // optional int32 num_threads = 1 [default = -1];
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _Internal::set_has_num_threads(&has_bits);
          num_threads_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  _has_bits_.Or(has_bits);
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferenceCalculatorOptions_Delegate_Xnnpack::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:mediapipe.InferenceCalculatorOptions.Delegate.Xnnpack)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // optional int32 num_threads = 1 [default = -1];
  if (cached_has_bits & 0x00000001u) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32ToArray(1, this->_internal_num_threads(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:mediapipe.InferenceCalculatorOptions.Delegate.Xnnpack)
  return target;
}

size_t InferenceCalculatorOptions_Delegate_Xnnpack::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:mediapipe.InferenceCalculatorOptions.Delegate.Xnnpack)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // optional int32 num_threads = 1 [default = -1];
  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32SizePlusOne(this->_internal_num_threads());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferenceCalculatorOptions_Delegate_Xnnpack::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferenceCalculatorOptions_Delegate_Xnnpack::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferenceCalculatorOptions_Delegate_Xnnpack::GetClassData() const { return &_class_data_; }

void InferenceCalculatorOptions_Delegate_Xnnpack::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferenceCalculatorOptions_Delegate_Xnnpack *>(to)->MergeFrom(
      static_cast<const InferenceCalculatorOptions_Delegate_Xnnpack &>(from));
}


void InferenceCalculatorOptions_Delegate_Xnnpack::MergeFrom(const InferenceCalculatorOptions_Delegate_Xnnpack& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:mediapipe.InferenceCalculatorOptions.Delegate.Xnnpack)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_has_num_threads()) {
    _internal_set_num_threads(from._internal_num_threads());
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferenceCalculatorOptions_Delegate_Xnnpack::CopyFrom(const InferenceCalculatorOptions_Delegate_Xnnpack& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:mediapipe.InferenceCalculatorOptions.Delegate.Xnnpack)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferenceCalculatorOptions_Delegate_Xnnpack::IsInitialized() const {
  return true;
}

void InferenceCalculatorOptions_Delegate_Xnnpack::InternalSwap(InferenceCalculatorOptions_Delegate_Xnnpack* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  swap(num_threads_, other->num_threads_);
}

::PROTOBUF_NAMESPACE_ID::Metadata InferenceCalculatorOptions_Delegate_Xnnpack::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_getter, &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_once,
      file_level_metadata_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto[3]);
}

// ===================================================================

class InferenceCalculatorOptions_Delegate::_Internal {
 public:
  static const ::mediapipe::InferenceCalculatorOptions_Delegate_TfLite& tflite(const InferenceCalculatorOptions_Delegate* msg);
  static const ::mediapipe::InferenceCalculatorOptions_Delegate_Gpu& gpu(const InferenceCalculatorOptions_Delegate* msg);
  static const ::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi& nnapi(const InferenceCalculatorOptions_Delegate* msg);
  static const ::mediapipe::InferenceCalculatorOptions_Delegate_Xnnpack& xnnpack(const InferenceCalculatorOptions_Delegate* msg);
};

const ::mediapipe::InferenceCalculatorOptions_Delegate_TfLite&
InferenceCalculatorOptions_Delegate::_Internal::tflite(const InferenceCalculatorOptions_Delegate* msg) {
  return *msg->delegate_.tflite_;
}
const ::mediapipe::InferenceCalculatorOptions_Delegate_Gpu&
InferenceCalculatorOptions_Delegate::_Internal::gpu(const InferenceCalculatorOptions_Delegate* msg) {
  return *msg->delegate_.gpu_;
}
const ::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi&
InferenceCalculatorOptions_Delegate::_Internal::nnapi(const InferenceCalculatorOptions_Delegate* msg) {
  return *msg->delegate_.nnapi_;
}
const ::mediapipe::InferenceCalculatorOptions_Delegate_Xnnpack&
InferenceCalculatorOptions_Delegate::_Internal::xnnpack(const InferenceCalculatorOptions_Delegate* msg) {
  return *msg->delegate_.xnnpack_;
}
void InferenceCalculatorOptions_Delegate::set_allocated_tflite(::mediapipe::InferenceCalculatorOptions_Delegate_TfLite* tflite) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_delegate();
  if (tflite) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::mediapipe::InferenceCalculatorOptions_Delegate_TfLite>::GetOwningArena(tflite);
    if (message_arena != submessage_arena) {
      tflite = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, tflite, submessage_arena);
    }
    set_has_tflite();
    delegate_.tflite_ = tflite;
  }
  // @@protoc_insertion_point(field_set_allocated:mediapipe.InferenceCalculatorOptions.Delegate.tflite)
}
void InferenceCalculatorOptions_Delegate::set_allocated_gpu(::mediapipe::InferenceCalculatorOptions_Delegate_Gpu* gpu) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_delegate();
  if (gpu) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::mediapipe::InferenceCalculatorOptions_Delegate_Gpu>::GetOwningArena(gpu);
    if (message_arena != submessage_arena) {
      gpu = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, gpu, submessage_arena);
    }
    set_has_gpu();
    delegate_.gpu_ = gpu;
  }
  // @@protoc_insertion_point(field_set_allocated:mediapipe.InferenceCalculatorOptions.Delegate.gpu)
}
void InferenceCalculatorOptions_Delegate::set_allocated_nnapi(::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi* nnapi) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_delegate();
  if (nnapi) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi>::GetOwningArena(nnapi);
    if (message_arena != submessage_arena) {
      nnapi = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, nnapi, submessage_arena);
    }
    set_has_nnapi();
    delegate_.nnapi_ = nnapi;
  }
  // @@protoc_insertion_point(field_set_allocated:mediapipe.InferenceCalculatorOptions.Delegate.nnapi)
}
void InferenceCalculatorOptions_Delegate::set_allocated_xnnpack(::mediapipe::InferenceCalculatorOptions_Delegate_Xnnpack* xnnpack) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  clear_delegate();
  if (xnnpack) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
      ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper<::mediapipe::InferenceCalculatorOptions_Delegate_Xnnpack>::GetOwningArena(xnnpack);
    if (message_arena != submessage_arena) {
      xnnpack = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, xnnpack, submessage_arena);
    }
    set_has_xnnpack();
    delegate_.xnnpack_ = xnnpack;
  }
  // @@protoc_insertion_point(field_set_allocated:mediapipe.InferenceCalculatorOptions.Delegate.xnnpack)
}
InferenceCalculatorOptions_Delegate::InferenceCalculatorOptions_Delegate(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:mediapipe.InferenceCalculatorOptions.Delegate)
}
InferenceCalculatorOptions_Delegate::InferenceCalculatorOptions_Delegate(const InferenceCalculatorOptions_Delegate& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  clear_has_delegate();
  switch (from.delegate_case()) {
    case kTflite: {
      _internal_mutable_tflite()->::mediapipe::InferenceCalculatorOptions_Delegate_TfLite::MergeFrom(from._internal_tflite());
      break;
    }
    case kGpu: {
      _internal_mutable_gpu()->::mediapipe::InferenceCalculatorOptions_Delegate_Gpu::MergeFrom(from._internal_gpu());
      break;
    }
    case kNnapi: {
      _internal_mutable_nnapi()->::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi::MergeFrom(from._internal_nnapi());
      break;
    }
    case kXnnpack: {
      _internal_mutable_xnnpack()->::mediapipe::InferenceCalculatorOptions_Delegate_Xnnpack::MergeFrom(from._internal_xnnpack());
      break;
    }
    case DELEGATE_NOT_SET: {
      break;
    }
  }
  // @@protoc_insertion_point(copy_constructor:mediapipe.InferenceCalculatorOptions.Delegate)
}

inline void InferenceCalculatorOptions_Delegate::SharedCtor() {
clear_has_delegate();
}

InferenceCalculatorOptions_Delegate::~InferenceCalculatorOptions_Delegate() {
  // @@protoc_insertion_point(destructor:mediapipe.InferenceCalculatorOptions.Delegate)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferenceCalculatorOptions_Delegate::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (has_delegate()) {
    clear_delegate();
  }
}

void InferenceCalculatorOptions_Delegate::ArenaDtor(void* object) {
  InferenceCalculatorOptions_Delegate* _this = reinterpret_cast< InferenceCalculatorOptions_Delegate* >(object);
  (void)_this;
}
void InferenceCalculatorOptions_Delegate::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferenceCalculatorOptions_Delegate::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferenceCalculatorOptions_Delegate::clear_delegate() {
// @@protoc_insertion_point(one_of_clear_start:mediapipe.InferenceCalculatorOptions.Delegate)
  switch (delegate_case()) {
    case kTflite: {
      if (GetArenaForAllocation() == nullptr) {
        delete delegate_.tflite_;
      }
      break;
    }
    case kGpu: {
      if (GetArenaForAllocation() == nullptr) {
        delete delegate_.gpu_;
      }
      break;
    }
    case kNnapi: {
      if (GetArenaForAllocation() == nullptr) {
        delete delegate_.nnapi_;
      }
      break;
    }
    case kXnnpack: {
      if (GetArenaForAllocation() == nullptr) {
        delete delegate_.xnnpack_;
      }
      break;
    }
    case DELEGATE_NOT_SET: {
      break;
    }
  }
  _oneof_case_[0] = DELEGATE_NOT_SET;
}


void InferenceCalculatorOptions_Delegate::Clear() {
// @@protoc_insertion_point(message_clear_start:mediapipe.InferenceCalculatorOptions.Delegate)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  clear_delegate();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferenceCalculatorOptions_Delegate::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // .mediapipe.InferenceCalculatorOptions.Delegate.TfLite tflite = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ctx->ParseMessage(_internal_mutable_tflite(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .mediapipe.InferenceCalculatorOptions.Delegate.Gpu gpu = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_gpu(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .mediapipe.InferenceCalculatorOptions.Delegate.Nnapi nnapi = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr = ctx->ParseMessage(_internal_mutable_nnapi(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // .mediapipe.InferenceCalculatorOptions.Delegate.Xnnpack xnnpack = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 34)) {
          ptr = ctx->ParseMessage(_internal_mutable_xnnpack(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferenceCalculatorOptions_Delegate::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:mediapipe.InferenceCalculatorOptions.Delegate)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  switch (delegate_case()) {
    case kTflite: {
      target = stream->EnsureSpace(target);
      target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(
          1, _Internal::tflite(this), target, stream);
      break;
    }
    case kGpu: {
      target = stream->EnsureSpace(target);
      target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(
          2, _Internal::gpu(this), target, stream);
      break;
    }
    case kNnapi: {
      target = stream->EnsureSpace(target);
      target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(
          3, _Internal::nnapi(this), target, stream);
      break;
    }
    case kXnnpack: {
      target = stream->EnsureSpace(target);
      target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(
          4, _Internal::xnnpack(this), target, stream);
      break;
    }
    default: ;
  }
  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:mediapipe.InferenceCalculatorOptions.Delegate)
  return target;
}

size_t InferenceCalculatorOptions_Delegate::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:mediapipe.InferenceCalculatorOptions.Delegate)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  switch (delegate_case()) {
    // .mediapipe.InferenceCalculatorOptions.Delegate.TfLite tflite = 1;
    case kTflite: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *delegate_.tflite_);
      break;
    }
    // .mediapipe.InferenceCalculatorOptions.Delegate.Gpu gpu = 2;
    case kGpu: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *delegate_.gpu_);
      break;
    }
    // .mediapipe.InferenceCalculatorOptions.Delegate.Nnapi nnapi = 3;
    case kNnapi: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *delegate_.nnapi_);
      break;
    }
    // .mediapipe.InferenceCalculatorOptions.Delegate.Xnnpack xnnpack = 4;
    case kXnnpack: {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *delegate_.xnnpack_);
      break;
    }
    case DELEGATE_NOT_SET: {
      break;
    }
  }
  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferenceCalculatorOptions_Delegate::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferenceCalculatorOptions_Delegate::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferenceCalculatorOptions_Delegate::GetClassData() const { return &_class_data_; }

void InferenceCalculatorOptions_Delegate::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferenceCalculatorOptions_Delegate *>(to)->MergeFrom(
      static_cast<const InferenceCalculatorOptions_Delegate &>(from));
}


void InferenceCalculatorOptions_Delegate::MergeFrom(const InferenceCalculatorOptions_Delegate& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:mediapipe.InferenceCalculatorOptions.Delegate)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  switch (from.delegate_case()) {
    case kTflite: {
      _internal_mutable_tflite()->::mediapipe::InferenceCalculatorOptions_Delegate_TfLite::MergeFrom(from._internal_tflite());
      break;
    }
    case kGpu: {
      _internal_mutable_gpu()->::mediapipe::InferenceCalculatorOptions_Delegate_Gpu::MergeFrom(from._internal_gpu());
      break;
    }
    case kNnapi: {
      _internal_mutable_nnapi()->::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi::MergeFrom(from._internal_nnapi());
      break;
    }
    case kXnnpack: {
      _internal_mutable_xnnpack()->::mediapipe::InferenceCalculatorOptions_Delegate_Xnnpack::MergeFrom(from._internal_xnnpack());
      break;
    }
    case DELEGATE_NOT_SET: {
      break;
    }
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferenceCalculatorOptions_Delegate::CopyFrom(const InferenceCalculatorOptions_Delegate& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:mediapipe.InferenceCalculatorOptions.Delegate)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferenceCalculatorOptions_Delegate::IsInitialized() const {
  return true;
}

void InferenceCalculatorOptions_Delegate::InternalSwap(InferenceCalculatorOptions_Delegate* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(delegate_, other->delegate_);
  swap(_oneof_case_[0], other->_oneof_case_[0]);
}

::PROTOBUF_NAMESPACE_ID::Metadata InferenceCalculatorOptions_Delegate::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_getter, &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_once,
      file_level_metadata_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto[4]);
}

// ===================================================================

class InferenceCalculatorOptions::_Internal {
 public:
  using HasBits = decltype(std::declval<InferenceCalculatorOptions>()._has_bits_);
  static void set_has_model_path(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
  static void set_has_use_gpu(HasBits* has_bits) {
    (*has_bits)[0] |= 4u;
  }
  static void set_has_use_nnapi(HasBits* has_bits) {
    (*has_bits)[0] |= 8u;
  }
  static void set_has_cpu_num_thread(HasBits* has_bits) {
    (*has_bits)[0] |= 16u;
  }
  static const ::mediapipe::InferenceCalculatorOptions_Delegate& delegate(const InferenceCalculatorOptions* msg);
  static void set_has_delegate(HasBits* has_bits) {
    (*has_bits)[0] |= 2u;
  }
};

const ::mediapipe::InferenceCalculatorOptions_Delegate&
InferenceCalculatorOptions::_Internal::delegate(const InferenceCalculatorOptions* msg) {
  return *msg->delegate_;
}
InferenceCalculatorOptions::InferenceCalculatorOptions(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor();
  if (!is_message_owned) {
    RegisterArenaDtor(arena);
  }
  // @@protoc_insertion_point(arena_constructor:mediapipe.InferenceCalculatorOptions)
}
InferenceCalculatorOptions::InferenceCalculatorOptions(const InferenceCalculatorOptions& from)
  : ::PROTOBUF_NAMESPACE_ID::Message(),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  model_path_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    model_path_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (from._internal_has_model_path()) {
    model_path_.Set(::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::EmptyDefault{}, from._internal_model_path(), 
      GetArenaForAllocation());
  }
  if (from._internal_has_delegate()) {
    delegate_ = new ::mediapipe::InferenceCalculatorOptions_Delegate(*from.delegate_);
  } else {
    delegate_ = nullptr;
  }
  ::memcpy(&use_gpu_, &from.use_gpu_,
    static_cast<size_t>(reinterpret_cast<char*>(&cpu_num_thread_) -
    reinterpret_cast<char*>(&use_gpu_)) + sizeof(cpu_num_thread_));
  // @@protoc_insertion_point(copy_constructor:mediapipe.InferenceCalculatorOptions)
}

inline void InferenceCalculatorOptions::SharedCtor() {
model_path_.UnsafeSetDefault(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  model_path_.Set(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(), "", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
::memset(reinterpret_cast<char*>(this) + static_cast<size_t>(
    reinterpret_cast<char*>(&delegate_) - reinterpret_cast<char*>(this)),
    0, static_cast<size_t>(reinterpret_cast<char*>(&use_nnapi_) -
    reinterpret_cast<char*>(&delegate_)) + sizeof(use_nnapi_));
cpu_num_thread_ = -1;
}

InferenceCalculatorOptions::~InferenceCalculatorOptions() {
  // @@protoc_insertion_point(destructor:mediapipe.InferenceCalculatorOptions)
  if (GetArenaForAllocation() != nullptr) return;
  SharedDtor();
  _internal_metadata_.Delete<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

inline void InferenceCalculatorOptions::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  model_path_.DestroyNoArena(&::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited());
  if (this != internal_default_instance()) delete delegate_;
}

void InferenceCalculatorOptions::ArenaDtor(void* object) {
  InferenceCalculatorOptions* _this = reinterpret_cast< InferenceCalculatorOptions* >(object);
  (void)_this;
}
void InferenceCalculatorOptions::RegisterArenaDtor(::PROTOBUF_NAMESPACE_ID::Arena*) {
}
void InferenceCalculatorOptions::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void InferenceCalculatorOptions::Clear() {
// @@protoc_insertion_point(message_clear_start:mediapipe.InferenceCalculatorOptions)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      model_path_.ClearNonDefaultToEmpty();
    }
    if (cached_has_bits & 0x00000002u) {
      GOOGLE_DCHECK(delegate_ != nullptr);
      delegate_->Clear();
    }
  }
  ::memset(&use_gpu_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&use_nnapi_) -
      reinterpret_cast<char*>(&use_gpu_)) + sizeof(use_nnapi_));
  cpu_num_thread_ = -1;
  _has_bits_.Clear();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* InferenceCalculatorOptions::_InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  _Internal::HasBits has_bits{};
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::PROTOBUF_NAMESPACE_ID::internal::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // optional string model_path = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          auto str = _internal_mutable_model_path();
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::InlineGreedyStringParser(str, ptr, ctx);
          #ifndef NDEBUG
          ::PROTOBUF_NAMESPACE_ID::internal::VerifyUTF8(str, "mediapipe.InferenceCalculatorOptions.model_path");
          #endif  // !NDEBUG
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional bool use_gpu = 2 [default = false, deprecated = true];
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _Internal::set_has_use_gpu(&has_bits);
          use_gpu_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional bool use_nnapi = 3 [default = false, deprecated = true];
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _Internal::set_has_use_nnapi(&has_bits);
          use_nnapi_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional int32 cpu_num_thread = 4 [default = -1];
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          _Internal::set_has_cpu_num_thread(&has_bits);
          cpu_num_thread_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional .mediapipe.InferenceCalculatorOptions.Delegate delegate = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 42)) {
          ptr = ctx->ParseMessage(_internal_mutable_delegate(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  _has_bits_.Or(has_bits);
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* InferenceCalculatorOptions::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:mediapipe.InferenceCalculatorOptions)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // optional string model_path = 1;
  if (cached_has_bits & 0x00000001u) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::VerifyUTF8StringNamedField(
      this->_internal_model_path().data(), static_cast<int>(this->_internal_model_path().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::SERIALIZE,
      "mediapipe.InferenceCalculatorOptions.model_path");
    target = stream->WriteStringMaybeAliased(
        1, this->_internal_model_path(), target);
  }

  // optional bool use_gpu = 2 [default = false, deprecated = true];
  if (cached_has_bits & 0x00000004u) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteBoolToArray(2, this->_internal_use_gpu(), target);
  }

  // optional bool use_nnapi = 3 [default = false, deprecated = true];
  if (cached_has_bits & 0x00000008u) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteBoolToArray(3, this->_internal_use_nnapi(), target);
  }

  // optional int32 cpu_num_thread = 4 [default = -1];
  if (cached_has_bits & 0x00000010u) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32ToArray(4, this->_internal_cpu_num_thread(), target);
  }

  // optional .mediapipe.InferenceCalculatorOptions.Delegate delegate = 5;
  if (cached_has_bits & 0x00000002u) {
    target = stream->EnsureSpace(target);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(
        5, _Internal::delegate(this), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:mediapipe.InferenceCalculatorOptions)
  return target;
}

size_t InferenceCalculatorOptions::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:mediapipe.InferenceCalculatorOptions)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x0000001fu) {
    // optional string model_path = 1;
    if (cached_has_bits & 0x00000001u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
          this->_internal_model_path());
    }

    // optional .mediapipe.InferenceCalculatorOptions.Delegate delegate = 5;
    if (cached_has_bits & 0x00000002u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *delegate_);
    }

    // optional bool use_gpu = 2 [default = false, deprecated = true];
    if (cached_has_bits & 0x00000004u) {
      total_size += 1 + 1;
    }

    // optional bool use_nnapi = 3 [default = false, deprecated = true];
    if (cached_has_bits & 0x00000008u) {
      total_size += 1 + 1;
    }

    // optional int32 cpu_num_thread = 4 [default = -1];
    if (cached_has_bits & 0x00000010u) {
      total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::Int32SizePlusOne(this->_internal_cpu_num_thread());
    }

  }
  return MaybeComputeUnknownFieldsSize(total_size, &_cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData InferenceCalculatorOptions::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSizeCheck,
    InferenceCalculatorOptions::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*InferenceCalculatorOptions::GetClassData() const { return &_class_data_; }

void InferenceCalculatorOptions::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message* to,
                      const ::PROTOBUF_NAMESPACE_ID::Message& from) {
  static_cast<InferenceCalculatorOptions *>(to)->MergeFrom(
      static_cast<const InferenceCalculatorOptions &>(from));
}


void InferenceCalculatorOptions::MergeFrom(const InferenceCalculatorOptions& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:mediapipe.InferenceCalculatorOptions)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 0x0000001fu) {
    if (cached_has_bits & 0x00000001u) {
      _internal_set_model_path(from._internal_model_path());
    }
    if (cached_has_bits & 0x00000002u) {
      _internal_mutable_delegate()->::mediapipe::InferenceCalculatorOptions_Delegate::MergeFrom(from._internal_delegate());
    }
    if (cached_has_bits & 0x00000004u) {
      use_gpu_ = from.use_gpu_;
    }
    if (cached_has_bits & 0x00000008u) {
      use_nnapi_ = from.use_nnapi_;
    }
    if (cached_has_bits & 0x00000010u) {
      cpu_num_thread_ = from.cpu_num_thread_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void InferenceCalculatorOptions::CopyFrom(const InferenceCalculatorOptions& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:mediapipe.InferenceCalculatorOptions)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool InferenceCalculatorOptions::IsInitialized() const {
  return true;
}

void InferenceCalculatorOptions::InternalSwap(InferenceCalculatorOptions* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &::PROTOBUF_NAMESPACE_ID::internal::GetEmptyStringAlreadyInited(),
      &model_path_, lhs_arena,
      &other->model_path_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(InferenceCalculatorOptions, use_nnapi_)
      + sizeof(InferenceCalculatorOptions::use_nnapi_)
      - PROTOBUF_FIELD_OFFSET(InferenceCalculatorOptions, delegate_)>(
          reinterpret_cast<char*>(&delegate_),
          reinterpret_cast<char*>(&other->delegate_));
  swap(cpu_num_thread_, other->cpu_num_thread_);
}

::PROTOBUF_NAMESPACE_ID::Metadata InferenceCalculatorOptions::GetMetadata() const {
  return ::PROTOBUF_NAMESPACE_ID::internal::AssignDescriptors(
      &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_getter, &descriptor_table_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto_once,
      file_level_metadata_mediapipe_2fcalculators_2ftensor_2finference_5fcalculator_2eproto[5]);
}
#if !defined(_MSC_VER) || (_MSC_VER >= 1900 && _MSC_VER < 1912)
const int InferenceCalculatorOptions::kExtFieldNumber;
#endif
PROTOBUF_ATTRIBUTE_INIT_PRIORITY ::PROTOBUF_NAMESPACE_ID::internal::ExtensionIdentifier< ::mediapipe::CalculatorOptions,
    ::PROTOBUF_NAMESPACE_ID::internal::MessageTypeTraits< ::mediapipe::InferenceCalculatorOptions >, 11, false >
  InferenceCalculatorOptions::ext(kExtFieldNumber, ::mediapipe::InferenceCalculatorOptions::default_instance());

// @@protoc_insertion_point(namespace_scope)
}  // namespace mediapipe
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::mediapipe::InferenceCalculatorOptions_Delegate_TfLite* Arena::CreateMaybeMessage< ::mediapipe::InferenceCalculatorOptions_Delegate_TfLite >(Arena* arena) {
  return Arena::CreateMessageInternal< ::mediapipe::InferenceCalculatorOptions_Delegate_TfLite >(arena);
}
template<> PROTOBUF_NOINLINE ::mediapipe::InferenceCalculatorOptions_Delegate_Gpu* Arena::CreateMaybeMessage< ::mediapipe::InferenceCalculatorOptions_Delegate_Gpu >(Arena* arena) {
  return Arena::CreateMessageInternal< ::mediapipe::InferenceCalculatorOptions_Delegate_Gpu >(arena);
}
template<> PROTOBUF_NOINLINE ::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi* Arena::CreateMaybeMessage< ::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi >(Arena* arena) {
  return Arena::CreateMessageInternal< ::mediapipe::InferenceCalculatorOptions_Delegate_Nnapi >(arena);
}
template<> PROTOBUF_NOINLINE ::mediapipe::InferenceCalculatorOptions_Delegate_Xnnpack* Arena::CreateMaybeMessage< ::mediapipe::InferenceCalculatorOptions_Delegate_Xnnpack >(Arena* arena) {
  return Arena::CreateMessageInternal< ::mediapipe::InferenceCalculatorOptions_Delegate_Xnnpack >(arena);
}
template<> PROTOBUF_NOINLINE ::mediapipe::InferenceCalculatorOptions_Delegate* Arena::CreateMaybeMessage< ::mediapipe::InferenceCalculatorOptions_Delegate >(Arena* arena) {
  return Arena::CreateMessageInternal< ::mediapipe::InferenceCalculatorOptions_Delegate >(arena);
}
template<> PROTOBUF_NOINLINE ::mediapipe::InferenceCalculatorOptions* Arena::CreateMaybeMessage< ::mediapipe::InferenceCalculatorOptions >(Arena* arena) {
  return Arena::CreateMessageInternal< ::mediapipe::InferenceCalculatorOptions >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
